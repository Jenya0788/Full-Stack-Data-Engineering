{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e53d931-2e14-4183-8f3a-30856e9a6f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Import required libraries\n",
    "import requests  # To send HTTP requests\n",
    "from lxml import etree  # To parse HTML content using XPath\n",
    "import pandas as pd  # To organize and save scraped data into Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f47ce07-bd8b-4e86-8b5e-030c6d022988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üõ†Ô∏è Connect to a web page and download its content\n",
    "def conn_web(url):\n",
    "    headers = {\n",
    "        \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)  # Send a GET request with headers\n",
    "        response.raise_for_status()  # Raise an error if status code is not 200\n",
    "        content = response.content.decode('UTF-8')  # Decode the content from bytes to UTF-8 string\n",
    "        return content\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error connecting to {url}: {e}\")\n",
    "        return None  # Return None if there‚Äôs any connection error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90c36830-de3e-4262-ba1a-aa9b86f23b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üõ†Ô∏è Extract post information and the next page URL using XPath\n",
    "def xpath_anchoring(content, data_list):\n",
    "    try:\n",
    "        html = etree.HTML(content)  # Parse the HTML content into a tree structure\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing HTML content: {e}\")\n",
    "        return data_list, None  # Return safely if parsing fails\n",
    "\n",
    "    # Locate big post elements (best practice: find the parent first)\n",
    "    posts = html.xpath(\"//div[@class='r-list-container action-bar-margin bbs-screen']/div[@class='r-ent']\")\n",
    "\n",
    "    # Try to locate the next page link\n",
    "    lastPage_url = html.xpath(\"//div[@class = 'btn-group btn-group-paging']/a[2]/@href\")\n",
    "    lastPage_url = f\"https://www.ptt.cc{lastPage_url[0]}\" if lastPage_url else None\n",
    "\n",
    "    # Loop through each post block and extract small fields\n",
    "    for post in posts:\n",
    "        title = post.xpath(\"./div[@class='title']/a/text()\")\n",
    "        title = title[0] if title else None  # Handle missing title\n",
    "\n",
    "        link = post.xpath(\"./div[@class='title']/a/@href\")\n",
    "        page_link = f\"https://www.ptt.cc{link[0]}\" if link else None  # Handle missing link\n",
    "\n",
    "        author = post.xpath(\"./div[@class='meta']/div[@class='author']/text()\")\n",
    "        author = author[0] if author else None  # Handle missing author\n",
    "\n",
    "        date = post.xpath(\"./div[@class='meta']/div[@class='date']/text()\")\n",
    "        date = date[0] if date else None  # Handle missing date\n",
    "\n",
    "        # Save extracted post data into the data list\n",
    "        post_data = {\n",
    "            \"title\": title,\n",
    "            \"page_link\": page_link,\n",
    "            \"author\": author,\n",
    "            \"date\": date\n",
    "        }\n",
    "        data_list.append(post_data)\n",
    "\n",
    "    return data_list, lastPage_url  # Return the updated data list and the next page URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5b78f11-11d6-4090-bfaf-75f656283e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üõ†Ô∏è Scrape multiple pages\n",
    "def public_static_pages_scraping(next_url, page_num):\n",
    "    data_list = []\n",
    "\n",
    "    for i in range(page_num):\n",
    "        content = conn_web(next_url)  # Connect to the current page\n",
    "        if content is None:\n",
    "            print(f\"Skipping page {i} due to connection error.\")  # Skip if connection fails\n",
    "            continue\n",
    "        data_list, next_url = xpath_anchoring(content, data_list)  # Extract posts and get the next page URL\n",
    "        \n",
    "        if not next_url:\n",
    "            break  # Stop if no next page is found\n",
    "\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1ea7a1b-71a8-4773-8b69-549173579fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# üöÄ Start scraping\n",
    "url = \"https://www.ptt.cc/bbs/Stock/index.html\"  # Starting URL (current stock board page)\n",
    "pageNum = 10  # How many pages you want to scrape\n",
    "\n",
    "data_list = public_static_pages_scraping(url, pageNum)  # Scrape the data\n",
    "data_list = pd.DataFrame(data_list)  # Convert the list of dicts into a DataFrame\n",
    "\n",
    "# üõ†Ô∏è Transform the page_link into Excel clickable hyperlinks\n",
    "data_list[\"page_link\"] = data_list.apply(\n",
    "    lambda x: f'=HYPERLINK(\"{x[\"page_link\"]}\", \"{x[\"page_link\"]}\")' if pd.notna(x[\"page_link\"]) else \"\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# üõ†Ô∏è Save the DataFrame into an Excel file\n",
    "try:\n",
    "    data_list.to_excel(\"output.xlsx\", index=False)\n",
    "    print(\"Excel file saved successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving Excel file: {e}\")  # Handle errors during Excel writing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e86ace-8edb-4472-8ae0-d8be582f2c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
